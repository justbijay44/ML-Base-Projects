{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d3d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efef51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dict = json.load(open('../kaggle/kaggle.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a093bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['username', 'key'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the username and key to authenticate\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_dict[\"username\"]\n",
    "os.environ['KAGGLE_KEY'] = kaggle_dict[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
      "License(s): other\n",
      "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# Downloading from kaggle\n",
    "\n",
    "# Running once is fine. Uncomment when required\n",
    "# !kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5e225cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Unzipping the file\n",
    "\n",
    "with ZipFile('imdb-dataset-of-50k-movie-reviews.zip', 'r') as f:\n",
    "    f.extractall(\"../data/imdb_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f218dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('../data/imdb_reviews/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147cff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "259ca5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['sentiment'] = sentiment_df['sentiment'].replace({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbdefd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95ab470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    24884\n",
       "0    24698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aab4b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(418)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df['review'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94f1c683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0281fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6feac",
   "metadata": {},
   "source": [
    "No null value and dropped duplicate as its a small number comapared to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68fc55",
   "metadata": {},
   "source": [
    "## Training and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0133a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(sentiment_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91f925f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4cedea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Tokenizer(num_words=5000)          # Getting 5000 most frequent words\n",
    "\n",
    "tokens.fit_on_texts(train_data['review'])   # So now each word in dataset are assigned a integer index\n",
    "\n",
    "X_train = pad_sequences(tokens.texts_to_sequences(train_data['review']), maxlen=200, padding='pre')   \n",
    "# padding are to ensure all sentences will have same shape as NN requires same shape\n",
    "\n",
    "X_test = pad_sequences(tokens.texts_to_sequences(test_data[\"review\"]), maxlen=200, padding='pre')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c036e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,   10,   64,  430,    1,\n",
       "         15,  993,  167,   18,  148,   11,   13,   37,  561,  343,    2,\n",
       "        315,  126,  323,  262, 4631,   17,    3,  601,   11,   15,   13,\n",
       "         74,   44,   37, 1319,  100, 1183,   10,  236,  437,    5,  884,\n",
       "        156,  407,   18,   10,   89,   56,  118,   48,  326,    5,  132,\n",
       "         10, 1454,    3,  373,    4,  212,   18,   61,   82,   10,   13,\n",
       "       2769,    3,   15,   37,   12,  141,   29,  222,   26,  155,   50,\n",
       "        126, 1961,    9,   13,   21,  274,   23,   39,  155,    2, 2016,\n",
       "       1045,   84,  713,  353,   95,   39, 1275,   17,    1,  167,   43,\n",
       "         22,  175,    3,  155, 1045,   15,  352,  156,    6,   11,  352,\n",
       "        202,  134], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0620845a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665, 200)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50700f",
   "metadata": {},
   "source": [
    "- As we have defined maxlen 200 so 200 cols\n",
    "- X_train[0] basically is a sentence the 0 means that this sentence doesnt have 200 words and the number basically is index of each word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b817b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['sentiment']\n",
    "y_test = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629dc46",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efa1f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "#Embedding\n",
    "model.add(Input(shape=(200,)))                              # as maxlen = 200\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))        # inp * o/p = 640,000\n",
    "\n",
    "#Lstm\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))    # 4 * ((128 + 128) * 128 + 128) = 131,584  -> gates((inp + neurons) * neurons + neurons)\n",
    "\n",
    "# Here the dropout drops 20% inputs at each training step\n",
    "# recurrent_dropout drops 20% memory carried from previous timestep\n",
    "# Both are to reduce overfitting\n",
    "\n",
    "#Dense\n",
    "model.add(Dense(1, activation='sigmoid'))                   # 128*1 + 1 = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7070e42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50347172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbd327",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2427d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 462ms/step - accuracy: 0.7821 - loss: 0.4623 - val_accuracy: 0.8571 - val_loss: 0.3461\n",
      "Epoch 2/5\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 258ms/step - accuracy: 0.8493 - loss: 0.3539 - val_accuracy: 0.8568 - val_loss: 0.3634\n",
      "Epoch 3/5\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 362ms/step - accuracy: 0.8835 - loss: 0.2892 - val_accuracy: 0.8620 - val_loss: 0.3481\n",
      "Epoch 4/5\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 343ms/step - accuracy: 0.8972 - loss: 0.2603 - val_accuracy: 0.8489 - val_loss: 0.3530\n",
      "Epoch 5/5\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 353ms/step - accuracy: 0.9093 - loss: 0.2296 - val_accuracy: 0.8674 - val_loss: 0.3398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b85741ce00>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f1ba2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.8678 - loss: 0.3371\n",
      "Loss: 0.3371107280254364\n",
      "Accuracy: 0.8678027391433716\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f5910",
   "metadata": {},
   "source": [
    "## Small Function to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "601b95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review):\n",
    "    seq = tokens.texts_to_sequences([review])\n",
    "    padded_seq = pad_sequences(seq, maxlen = 200)\n",
    "    prediction = model.predict(padded_seq)\n",
    "    sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1398f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "The sentiment of the review is: Positive\n"
     ]
    }
   ],
   "source": [
    "myreview = \"The overall series is pretty good !!\"\n",
    "sentiment = predict_sentiment(myreview)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e025212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "The sentiment of the review is: Negative\n"
     ]
    }
   ],
   "source": [
    "myreview = \"The series is was boring!!\"\n",
    "sentiment = predict_sentiment(myreview)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c255dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "The sentiment of the review is: Negative\n"
     ]
    }
   ],
   "source": [
    "myreview = \"The series is wasnt to my taste !!\"\n",
    "sentiment = predict_sentiment(myreview)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81304a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "The sentiment of the review is: Positive\n"
     ]
    }
   ],
   "source": [
    "myreview = \"The series is was fine !!\"\n",
    "sentiment = predict_sentiment(myreview)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fb465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
